{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MedDSL-Lite 3-Arm Evaluation\n",
        "\n",
        "This notebook implements the 3-arm evaluation comparing LLM-only, Rules-only, and Hybrid approaches for diabetic retinopathy triage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import random\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "# Add the parent directory to the path to import mddsl\n",
        "sys.path.append(str(Path.cwd().parent))\n",
        "\n",
        "from mddsl import execute, explain, SnippetRetriever\n",
        "from mddsl.interpreter import load_dsl_from_file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load DSL rules and cases\n",
        "dsl = load_dsl_from_file(\"../rules/dr_triage_v1.yaml\")\n",
        "retriever = SnippetRetriever(\"../snippets\")\n",
        "\n",
        "# Load test cases\n",
        "cases = []\n",
        "with open(\"../data/cases_small.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        if line.strip():\n",
        "            cases.append(json.loads(line))\n",
        "\n",
        "print(f\"Loaded {len(cases)} test cases\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLM-Only Arm (Simulated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_llm_only(case: Dict[str, Any], k: int = 5) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Simulate LLM-only responses with some variability.\n",
        "    In practice, this would call an actual LLM API.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    # Extract case features\n",
        "    dr_grade = case.get(\"dr_grade\")\n",
        "    edema_prob = case.get(\"macula\", {}).get(\"edema_prob\")\n",
        "    vision_reduced = case.get(\"vision_reduced\", False)\n",
        "    qc_pass = case.get(\"qc\", {}).get(\"fundus_pass\", False) and case.get(\"qc\", {}).get(\"macula_view\", False)\n",
        "    \n",
        "    for i in range(k):\n",
        "        # Simulate some variability in LLM responses\n",
        "        if not qc_pass:\n",
        "            decision = \"abstain\"\n",
        "            rationale = \"QC failure - insufficient image quality\"\n",
        "        elif dr_grade in [\"pdr\", \"severe_npdr\"]:\n",
        "            decision = \"retina referral (urgent)\"\n",
        "            rationale = f\"Severe DR grade {dr_grade} requires urgent retina specialist evaluation\"\n",
        "        elif dr_grade == \"moderate_npdr\":\n",
        "            decision = \"retina referral (2-4 weeks)\"\n",
        "            rationale = \"Moderate NPDR requires referral for ophthalmic evaluation\"\n",
        "        elif edema_prob and edema_prob >= 0.70:\n",
        "            decision = \"retina referral (2-4 weeks)\"\n",
        "            rationale = f\"High edema probability {edema_prob} suggests DME, requires OCT and referral\"\n",
        "        elif vision_reduced:\n",
        "            decision = \"follow-up (3m)\"\n",
        "            rationale = \"Vision reduction requires earlier follow-up\"\n",
        "        else:\n",
        "            decision = \"follow-up (12m)\"\n",
        "            rationale = \"Mild or no DR, routine follow-up appropriate\"\n",
        "        \n",
        "        # Add some variability (simulate LLM inconsistency)\n",
        "        if random.random() < 0.2:  # 20% chance of different decision\n",
        "            alternatives = [\"retina referral (urgent)\", \"retina referral (2-4 weeks)\", \"follow-up (6m)\", \"follow-up (12m)\"]\n",
        "            if decision in alternatives:\n",
        "                decision = random.choice([alt for alt in alternatives if alt != decision])\n",
        "        \n",
        "        results.append({\n",
        "            \"decision\": decision,\n",
        "            \"rationale\": rationale,\n",
        "            \"thresholds_mentioned\": \"edema_prob â‰¥ 0.70\" in rationale or \"DR grade\" in rationale,\n",
        "            \"citations\": [\"AAO PPP: Diabetic Retinopathy\"] if \"DR\" in rationale else []\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run LLM-only evaluation\n",
        "llm_results = []\n",
        "for i, case in enumerate(cases):\n",
        "    case_results = simulate_llm_only(case, k=5)\n",
        "    for j, result in enumerate(case_results):\n",
        "        llm_results.append({\n",
        "            \"case_id\": i,\n",
        "            \"run_id\": j,\n",
        "            \"arm\": \"LLM-only\",\n",
        "            **result\n",
        "        })\n",
        "\n",
        "print(f\"Generated {len(llm_results)} LLM-only responses\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
